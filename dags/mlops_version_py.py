# -*- coding: utf-8 -*-
"""MLOps_version.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jg5f0chJSFV9Esw79v_2rJaS74j_PAh1
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import os
import pickle
import json


# Função para calcular limites de outliers
def lim_outliers(coluna):
    import pandas as pd
    q1 = coluna.quantile(0.25)
    q3 = coluna.quantile(0.75)
    iqr = q3 - q1
    lim_inf = q1 - (1.5 * iqr)
    lim_sup = q3 + (1.5 * iqr)
    return pd.Series([lim_inf, lim_sup], index=["lim_inf", "lim_sup"])

# Função para avaliação de modelo com validação cruzada
def evaluate_model_with_cv(model, X, y, cv=5):
    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)
    return scores.mean(), scores.std()

# Set MLFlow URI
def mlflow_setup():
    import mlflow

    mlflow_port = os.getenv("MLFLOW_PORT")
    mlflow.set_tracking_uri(f"http://mlflow:{mlflow_port}")
    mlflow.set_experiment("MLOps Demo")

def log_classification_report(cr):
    import mlflow

    # Logging all metrics in classification_report
    mlflow.log_metric("accuracy", cr.pop("accuracy"))
    for class_or_avg, metrics_dict in cr.items():
        for metric, value in metrics_dict.items():
            mlflow.log_metric(class_or_avg + '_' + metric,value)

# Task: Preparação dos dados de treino
def prepare_data_train(**context):
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import StandardScaler, LabelEncoder

    df = pd.read_csv("dags/predictive_maintenance.csv")
    print("Data extracted!")

    df = df.drop(columns=["UDI"])
    df_grouped = df.groupby("Type").agg(
        lim_inf_air_temp=("Air temperature [K]", lambda x: lim_outliers(x)["lim_inf"]),
        lim_sup_air_temp=("Air temperature [K]", lambda x: lim_outliers(x)["lim_sup"]),
        lim_inf_process_temp=("Process temperature [K]", lambda x: lim_outliers(x)["lim_inf"]),
        lim_sup_process_temp=("Process temperature [K]", lambda x: lim_outliers(x)["lim_sup"]),
        lim_inf_rotational_speed=("Rotational speed [rpm]", lambda x: lim_outliers(x)["lim_inf"]),
        lim_sup_rotational_speed=("Rotational speed [rpm]", lambda x: lim_outliers(x)["lim_sup"]),
        lim_inf_torque=("Torque [Nm]", lambda x: lim_outliers(x)["lim_inf"]),
        lim_sup_torque=("Torque [Nm]", lambda x: lim_outliers(x)["lim_sup"]),
        lim_inf_tw=("Tool wear [min]", lambda x: lim_outliers(x)["lim_inf"]),
        lim_sup_tw=("Tool wear [min]", lambda x: lim_outliers(x)["lim_sup"])
    ).reset_index()
    df_outlier = df.drop(columns="Target").merge(df_grouped, on=["Type"])

    i = 8
    for col in ["Air temperature [K]", "Process temperature [K]", "Rotational speed [rpm]", "Torque [Nm]", "Tool wear [min]"]:
        df_outlier[col] = np.where(
            (df_outlier[col] < df_outlier.iloc[:, i]) | (df_outlier[col] > df_outlier.iloc[:, i + 1]),
            True,
            False
        )
        i += 2
    df_outlier = df_outlier.drop(columns=[
        "lim_inf_air_temp", "lim_sup_air_temp", "lim_inf_process_temp", "lim_sup_process_temp",
        "lim_inf_rotational_speed", "lim_sup_rotational_speed", "lim_inf_torque", "lim_sup_torque",
        "lim_inf_tw", "lim_sup_tw"
    ])
    df_outlier["remove"] = np.where(
        ((df_outlier["Rotational speed [rpm]"] == True) | (df_outlier["Torque [Nm]"] == True)) &
        (df_outlier["Failure Type"] != "Power Failure"),
        True,
        False
    )
    df_removed_outliers = df_outlier[df_outlier["remove"] == False]
    ids_mantidos = df_removed_outliers["Product ID"]
    df_no_outlier = df[df["Product ID"].isin(ids_mantidos)]

    print("Outliers removed")

    df_padronizado = df_no_outlier.copy()
    df_padronizado["UDI"] = 1
    dummies_type = pd.get_dummies(df_padronizado["Type"], prefix="type", drop_first=True).astype(int)
    df_padronizado = pd.concat([df_padronizado, dummies_type], axis=1)
    df_padronizado = df_padronizado.drop(columns=["Product ID", "Type", "UDI"])
    col_padronizar = df_padronizado.drop(columns=["Failure Type", "Target"]).columns
    scaler = StandardScaler()
    df_padronizado[col_padronizar] = scaler.fit_transform(df_padronizado[col_padronizar])
    encoder = LabelEncoder()
    df_padronizado["Failure Type"] = encoder.fit_transform(df_padronizado["Failure Type"])

    print("Dataset padronized")

    df_padronizado.to_csv(f"{context['dag_run'].run_id}_df_padronizado.csv", index=False)

# Task: Divisão dos dados para treino e teste
def train_test_bin_model(**context):
    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split

    print("Spliting train test datasets")
    df_padronizado = pd.read_csv(f"{context['dag_run'].run_id}_df_padronizado.csv")
    X = df_padronizado.drop(columns=["Failure Type", "Target"])
    Y = df_padronizado["Target"]

    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
    np.save(f"{context['dag_run'].run_id}_x_train.npy", x_train)
    np.save(f"{context['dag_run'].run_id}_x_test.npy", x_test)
    np.save(f"{context['dag_run'].run_id}_y_train.npy", y_train)
    np.save(f"{context['dag_run'].run_id}_y_test.npy", y_test)

    print("x_train, x_test, y_train, y_test ready")

# Task: Treinamento do melhor modelo binário
def train_best_model_bin(**context):
    import numpy as np
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.ensemble import RandomForestClassifier

    print("Searching best binary model")
    x_train = np.load(f"{context['dag_run'].run_id}_x_train.npy", allow_pickle=True)
    y_train = np.load(f"{context['dag_run'].run_id}_y_train.npy", allow_pickle=True)

    models_setup = {
        "Logistic Regression - Pesos automáticos": {
            "tag": "logistic_regression_auto_weights",
            "class": LogisticRegression,
            "params": {
                "random_state": 42,
                "max_iter": 4000,
                "class_weight": "balanced",
            },
        },
        "Logistic Regression - Pesos manuais": {
            "tag": "logistic_regression_manual_weights",
            "class": LogisticRegression,
            "params": {
                "class_weight": {0: 0.507901, 1: 2.955361},
                "max_iter": 4000
            },
        },
        "KNN": {
            "tag": "knn",
            "class": KNeighborsClassifier,
            "params": {
                "n_neighbors": 3
            },
        },
        "RandomForestClassifier": {
            "tag": "random_forest",
            "class": RandomForestClassifier,
            "params": {
                "class_weight": {0: 0.697901, 1: 11.955361}
            },
        },
    }
    models_bin = {
        model_name: model_setup["class"](**model_setup["params"])
        for model_name, model_setup in models_setup.items()
    }
    model_scores = {}
    metrics = {}

    for model_name in models_setup:
        model = models_bin[model_name]
        model_tag = models_setup[model_name]["tag"]

        # Evaluate model
        mean_score, std_score = evaluate_model_with_cv(model, x_train, y_train)
        model_scores[model_name] = (mean_score, std_score)

        metrics[f"{model_tag}_cv_mean_accuracy"] = mean_score
        metrics[f"{model_tag}_cv_std_accuracy"] = std_score

    # Select best model based on cross-validation
    best_model_name = max(model_scores, key=lambda x: model_scores[x][0])
    best_model = models_bin[best_model_name]
    print(f"Best model found: {best_model}")

    (best_mean_score, best_std_score) = model_scores[best_model_name]
    metrics["selected_cv_mean_accuracy"] = best_mean_score
    metrics["selected_cv_std_accuracy"] = best_std_score

    # Fit train data
    best_model.fit(x_train, y_train)

    with open(f"{context['dag_run'].run_id}_model_binary.pkl", "wb") as f:
        pickle.dump(best_model, f)

    with open(f"{context['dag_run'].run_id}_model_params.json", "w") as f:
        model_params = {
            "model": best_model_name,
            "train_date": context["logical_date"].isoformat(),
            **models_setup[best_model_name]["params"],
        }
        json.dump(model_params, f)

    with open(f"{context['dag_run'].run_id}_model_selection_metrics.json", "w") as f:
        json.dump(metrics, f)

    print("Model trained and saved")

# Task: Predição nos dados de teste
def predict_on_test_data(**context):
    import numpy as np

    with open(f"{context['dag_run'].run_id}_model_binary.pkl", "rb") as f:
        binary_model = pickle.load(f)
    x_test = np.load(f"{context['dag_run'].run_id}_x_test.npy", allow_pickle=True)
    y_pred = binary_model.predict(x_test)
    np.save(f"{context['dag_run'].run_id}_y_pred.npy", y_pred)
    print("Predicted classes in test dataset")

# Task: Carregamento das métricas no MLFlow
def load_metrics(**context):
    import numpy as np
    from sklearn.metrics import classification_report
    import mlflow
    from mlflow.models import infer_signature

    with open(f"{context['dag_run'].run_id}_model_binary.pkl", "rb") as f:
        binary_model = pickle.load(f)
    x_train = np.load(f"{context['dag_run'].run_id}_x_train.npy", allow_pickle=True)
    y_test = np.load(f"{context['dag_run'].run_id}_y_test.npy", allow_pickle=True)
    y_pred = np.load(f"{context['dag_run'].run_id}_y_pred.npy", allow_pickle=True)
    cr = classification_report(y_test, y_pred, output_dict=True)
    print(cr)

    mlflow_setup()
    with mlflow.start_run():
        # Log the hyperparameters
        with open(f"{context['dag_run'].run_id}_model_params.json", "r") as f:
            model_params = json.load(f)
        mlflow.log_params(params=model_params)

        # Log the model selection metrics
        with open(f"{context['dag_run'].run_id}_model_selection_metrics.json", "r") as f:
            model_metrics = json.load(f)
        for name, value in model_metrics.items():
            mlflow.log_metric(name, value)

        # Log the classification report
        log_classification_report(cr)

        # Infer the model signature
        signature = infer_signature(x_train, binary_model.predict(x_train))

        # Log the model
        mlflow.sklearn.log_model(
            sk_model=binary_model,
            artifact_path="mlops_demo",
            signature=signature,
            input_example=x_train,
            registered_model_name="mlops_demo",
        )


# Configuração da DAG
with DAG(
    dag_id="predictive_maintenance_pipeline",
    start_date=datetime(2023, 1, 1),
    schedule_interval="@daily",
    catchup=False
) as dag:

    t1 = PythonOperator(
        task_id="prepare_data_train",
        python_callable=prepare_data_train,
        provide_context=True,
    )

    t2 = PythonOperator(
        task_id="train_test_bin_model",
        python_callable=train_test_bin_model,
        provide_context=True,
    )

    t3 = PythonOperator(
        task_id="train_best_model_bin",
        python_callable=train_best_model_bin,
        provide_context=True,
    )

    t4 = PythonOperator(
        task_id="predict_on_test_data",
        python_callable=predict_on_test_data,
        provide_context=True,
    )

    t5 = PythonOperator(
        task_id="get_metrics",
        python_callable=load_metrics,
        provide_context=True,
    )

    # Definindo a sequência de execução
    t1 >> t2 >> t3 >> t4 >> t5